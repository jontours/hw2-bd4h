{"paragraphs":[{"text":"%md ##Event Statistics using Scala","dateUpdated":"2018-02-11T02:30:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>##Event Statistics using Scala</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518316249790_1477808773","id":"20170126-084346_411967885","dateCreated":"2018-02-11T02:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:519"},{"title":"Event Statistics using Scala","text":"// any import statements go here\nimport org.apache.spark.rdd.RDD\nimport org.apache.commons.io.IOUtils\nimport java.text.SimpleDateFormat\nimport java.util.Date\nimport java.net.URL\nimport java.nio.charset.Charset\nimport org.apache.spark.sql._\nimport scala.collection.mutable.ListBuffer\n","user":"anonymous","dateUpdated":"2018-02-11T02:44:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","colWidth":12,"title":false,"results":{},"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd.RDD\nimport org.apache.commons.io.IOUtils\nimport java.text.SimpleDateFormat\nimport java.util.Date\nimport java.net.URL\nimport java.nio.charset.Charset\nimport org.apache.spark.sql._\nimport scala.collection.mutable.ListBuffer\n"}]},"apps":[],"jobName":"paragraph_1518316249796_1461649319","id":"20170125-092928_572765858","dateCreated":"2018-02-11T02:30:49+0000","dateStarted":"2018-02-11T02:44:46+0000","dateFinished":"2018-02-11T02:45:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:520"},{"title":"Then, load data. We uploaded the data on S3 for easier loading","text":"// load raw data\n\ndef loadFromUrl(url:String) = \n    sc.parallelize(\n        IOUtils.toString(\n            new URL(url),\n            Charset.forName(\"utf8\")).split(\"\\n\"))\n            \n//val events = loadFromUrl(\"http://sunlab.org/download/course/hw2/events.csv\")\n//val mortality = loadFromUrl(\"http://sunlab.org/download/course/hw2/mortality.csv\")\nval events = sc.textFile(\"file:///mnt/host/home/jontours/data/events.csv\")\nval mortality = sc.textFile(\"file:///mnt/host/home/jontours/data/mortality.csv\")","user":"anonymous","dateUpdated":"2018-02-11T02:58:57+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","colWidth":12,"title":true,"results":{},"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"loadFromUrl: (url: String)org.apache.spark.rdd.RDD[String]\nevents: org.apache.spark.rdd.RDD[String] = file:///mnt/host/home/jontours/data/events.csv MapPartitionsRDD[11] at textFile at <console>:41\nmortality: org.apache.spark.rdd.RDD[String] = file:///mnt/host/home/jontours/data/mortality.csv MapPartitionsRDD[13] at textFile at <console>:38\n"}]},"apps":[],"jobName":"paragraph_1518316249797_1461264570","id":"20170125-102007_1054430570","dateCreated":"2018-02-11T02:30:49+0000","dateStarted":"2018-02-11T02:58:58+0000","dateFinished":"2018-02-11T02:58:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:521"},{"text":"import java.util.Date\n// Define case class\ncase class Event(patientId: String, category: String, event: String, date: java.util.Date, value: Double)\ncase class Mortality(patientId: String, mortality_date:  java.util.Date, label: Double)\n","user":"anonymous","dateUpdated":"2018-02-11T02:59:01+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.util.Date\ndefined class Event\ndefined class Mortality\n"}]},"apps":[],"jobName":"paragraph_1518316249798_1462418817","id":"20170125-093656_1081259042","dateCreated":"2018-02-11T02:30:49+0000","dateStarted":"2018-02-11T02:59:01+0000","dateFinished":"2018-02-11T02:59:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:522"},{"text":"\n// Define date format\nval dateFormat = new SimpleDateFormat(\"yyyy-MM-dd\")","user":"anonymous","dateUpdated":"2018-02-11T02:59:07+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dateFormat: java.text.SimpleDateFormat = java.text.SimpleDateFormat@f67a0200\n"}]},"apps":[],"jobName":"paragraph_1518316249798_1462418817","id":"20170205-182828_2037956217","dateCreated":"2018-02-11T02:30:49+0000","dateStarted":"2018-02-11T02:59:07+0000","dateFinished":"2018-02-11T02:59:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:523"},{"text":"\n// Load events & mortality into their corresponding RDD\nval eventsRDD: RDD[Event] = events.map(s=>s.split(\",\")).map(s=>Event(s(0), s(1), s(2),dateFormat.parse(s(3).asInstanceOf[String]), if (s.length > 4) s(4).toDouble else 0.0))\nval mortalityRDD: RDD[Mortality] = mortality.map(s=>s.split(\",\")).map(s=>Mortality(s(0), dateFormat.parse(s(1).asInstanceOf[String]), s(2).toDouble))","user":"anonymous","dateUpdated":"2018-02-11T02:59:09+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","colWidth":12,"results":{},"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"eventsRDD: org.apache.spark.rdd.RDD[Event] = MapPartitionsRDD[15] at map at <console>:47\nmortalityRDD: org.apache.spark.rdd.RDD[Mortality] = MapPartitionsRDD[17] at map at <console>:45\n"}]},"apps":[],"jobName":"paragraph_1518316249799_1462034068","id":"20170125-103206_1230836042","dateCreated":"2018-02-11T02:30:49+0000","dateStarted":"2018-02-11T02:59:09+0000","dateFinished":"2018-02-11T02:59:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:524"},{"title":"Event count is defined as the number of events recorded for a given patient","text":"//def getCountBuffer(sumResults: Array[(String, Int)]) : (ListBuffer[Patient]) = {\n    \n//}\n\n\ndef event_count_metrics(eve: RDD[(Event)], mor: RDD[(Mortality)]) : (Double, Double, Double, Double, Double, Double) = {\n    val keyedEve = eve.keyBy(filtered_event => filtered_event.patientId)\n    val keyedMor = mor.keyBy(mortality => mortality.patientId)\n    \n    val deadEvents = keyedEve.join(keyedMor)\n    val aliveEvents = keyedEve.subtractByKey(deadEvents)\n    // val alive = aliveEvents.values()\n    // val dead = deadEVents.values()\n    \n    val initialCount = 0;\n    val addToCounts = (n: Int, v: (Event,Mortality)) => n + 1\n    val addToAliveCounts = (n: Int, v: (Event)) => n + 1\n    val sumPartitionCounts = (p1: Int, p2: Int) => p1 + p2\n\n    val countByKey = deadEvents.aggregateByKey(initialCount)(addToCounts, sumPartitionCounts)\n    val aliveCountByKey = aliveEvents.aggregateByKey(initialCount)(addToAliveCounts, sumPartitionCounts)\n    case class Patient(patientId: String, count: Int)\n    \n    val sumResults = countByKey.collect()\n    var patients = new ListBuffer[Patient]()\n    var deadTotal = 0.0\n    for(indx <- sumResults.indices){\n        val r = sumResults(indx)\n        //println(r._1 + \" -> \" + r._2)\n        patients += Patient(r._1, r._2)\n        deadTotal += r._2\n    }\n    \n    val aliveSumResults = aliveCountByKey.collect()\n    var alivePatients = new ListBuffer[Patient]()\n    var aliveTotal = 0.0\n    for(indx <- aliveSumResults.indices){\n        val r = aliveSumResults(indx)\n        alivePatients += Patient(r._1, r._2)\n        aliveTotal += r._2\n    }\n    \n    \n    def max(p1: Patient, p2: Patient): Patient = if (p1.count > p2.count) p1 else p2\n    def min(p1: Patient, p2: Patient): Patient = if (p1.count < p2.count) p1 else p2\n    \n    val patientsList = patients.toList\n    val maxDead = patientsList.reduceLeft(max)\n    val minDead = patientsList.reduceLeft(min)\n    val deadAverage = deadTotal / patientsList.length\n    \n    val alivePatientsList = alivePatients.toList\n    val maxAlive = alivePatients.reduceLeft(max)\n    val minAlive = alivePatients.reduceLeft(min)\n    val aliveAverage = aliveTotal / alivePatientsList.length\n\n    val avg_dead_event_count = deadAverage\n    val max_dead_event_count = maxDead.count\n    val min_dead_event_count = minDead.count\n    val avg_alive_event_count = aliveAverage\n    val max_alive_event_count = maxAlive.count\n    val min_alive_event_count = minAlive.count\n    \n    (avg_dead_event_count, max_dead_event_count, min_dead_event_count, avg_alive_event_count, max_alive_event_count, min_alive_event_count)\n}","user":"anonymous","dateUpdated":"2018-02-11T02:59:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","colWidth":12,"title":true,"results":{},"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"event_count_metrics: (eve: org.apache.spark.rdd.RDD[Event], mor: org.apache.spark.rdd.RDD[Mortality])(Double, Double, Double, Double, Double, Double)\n"}]},"apps":[],"jobName":"paragraph_1518316249799_1462034068","id":"20170125-163824_794924019","dateCreated":"2018-02-11T02:30:49+0000","dateStarted":"2018-02-11T02:59:15+0000","dateFinished":"2018-02-11T02:59:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:525"},{"title":"Encounter count is defined as the count of unique dates on which a given patient visited the ICU. ","text":"def encounter_count_metrics(eve: RDD[(Event)], mor: RDD[(Mortality)]) : (Double, Double, Double, Double, Double, Double) = {\n    val keyedEve = eve.keyBy(filtered_event => filtered_event.patientId)\n    val keyedMor = mor.keyBy(mortality => mortality.patientId)\n    \n    val deadEvents = keyedEve.join(keyedMor)\n    val aliveEvents = keyedEve.subtractByKey(deadEvents)\n     \n    \n    val deadEventsWithDate = deadEvents.keyBy(deadEvent => (deadEvent._2._1.patientId, deadEvent._2._1.date))\n    val groupedDeadEvents = deadEventsWithDate.groupByKey().mapValues(x => (1)).keyBy(deadEvent => deadEvent._1._1)\n    \n    val aliveEventsWithDate = aliveEvents.keyBy(aliveEvent => (aliveEvent._2.patientId, aliveEvent._2.date))\n    val groupedAliveEvents = aliveEventsWithDate.groupByKey().mapValues(x => (1)).keyBy(deadEvent => deadEvent._1._1)\n    \n    val initialCount = 0;\n    val addToCounts = (n: Int, v: ((String, java.util.Date), Int)) => n + 1\n    val addToAliveCounts = (n: Int, v:((String, Event))) => n + 1\n    val sumPartitionCounts = (p1: Int, p2: Int) => p1 + p2\n\n    val countByKey = groupedDeadEvents.aggregateByKey(initialCount)(addToCounts, sumPartitionCounts)\n    \n    val aliveCountByKey = groupedAliveEvents.aggregateByKey(initialCount)(addToCounts, sumPartitionCounts)\n    \n    case class Patient(patientId: String, count: Int)\n    \n    val sumResults = countByKey.collect()\n    var patients = new ListBuffer[Patient]()\n    var deadTotal = 0.0\n    for(indx <- sumResults.indices){\n        val r = sumResults(indx)\n        patients += Patient(r._1, r._2)\n        deadTotal += r._2\n    }\n    \n    def max(p1: Patient, p2: Patient): Patient = if (p1.count > p2.count) p1 else p2\n    def min(p1: Patient, p2: Patient): Patient = if (p1.count < p2.count) p1 else p2\n    \n    val patientsList = patients.toList\n    val maxDead = patientsList.reduceLeft(max)\n    val minDead = patientsList.reduceLeft(min)\n    val deadAverage = deadTotal / patientsList.length\n    \n    val aliveSumResults = aliveCountByKey.collect()\n    var alivePatients = new ListBuffer[Patient]()\n    var aliveTotal = 0.0\n    for(indx <- aliveSumResults.indices){\n        val r = aliveSumResults(indx)\n        alivePatients += Patient(r._1, r._2)\n        aliveTotal += r._2\n    }\n    \n    val alivePatientsList = alivePatients.toList\n    val maxAlive = alivePatients.reduceLeft(max)\n    val minAlive = alivePatients.reduceLeft(min)\n    val aliveAverage = aliveTotal / alivePatientsList.length\n    \n    \n    // TODO : Implement this function to return the encounter count metrics.\n    val avg_dead_encounter_count = deadAverage\n    val max_dead_encounter_count = maxDead.count\n    val min_dead_encounter_count = minDead.count\n    val avg_alive_encounter_count = aliveAverage\n    val max_alive_encounter_count = maxAlive.count\n    val min_alive_encounter_count = minAlive.count\n    \n    (avg_dead_encounter_count, max_dead_encounter_count, min_dead_encounter_count, avg_alive_encounter_count, max_alive_encounter_count, min_alive_encounter_count)\n}","user":"anonymous","dateUpdated":"2018-02-11T02:59:21+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"encounter_count_metrics: (eve: org.apache.spark.rdd.RDD[Event], mor: org.apache.spark.rdd.RDD[Mortality])(Double, Double, Double, Double, Double, Double)\n"}]},"apps":[],"jobName":"paragraph_1518316249800_1460110323","id":"20170126-094037_1369751422","dateCreated":"2018-02-11T02:30:49+0000","dateStarted":"2018-02-11T02:59:21+0000","dateFinished":"2018-02-11T02:59:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:526"},{"title":"Testing Event Count - Don't change this cell","text":"\nval (avg_dead_event_count, max_dead_event_count, min_dead_event_count, avg_alive_event_count, max_alive_event_count, min_alive_event_count) = \nevent_count_metrics(eventsRDD, mortalityRDD)\n","user":"anonymous","dateUpdated":"2018-02-11T02:59:29+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"avg_dead_event_count: Double = 1027.7385229540919\nmax_dead_event_count: Double = 16829.0\nmin_dead_event_count: Double = 2.0\navg_alive_event_count: Double = 683.1552587646077\nmax_alive_event_count: Double = 12627.0\nmin_alive_event_count: Double = 1.0\n"}]},"apps":[],"jobName":"paragraph_1518316249800_1460110323","id":"20170125-164106_1373358169","dateCreated":"2018-02-11T02:30:49+0000","dateStarted":"2018-02-11T02:59:29+0000","dateFinished":"2018-02-11T03:00:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:527"},{"title":"Populate the correct values in df_events dataframe","text":"case class eventRecord(Average_Event: Double , Max_Event: Double, Min_Event: Double, Mortality: String) \n\n// TODO - Fill in the correct values of minimum, maximum and average events for Alive and Dead Patients \nval df_events = Seq(eventRecord(avg_alive_event_count, max_alive_event_count, min_alive_event_count, \"Alive\"), eventRecord(avg_dead_event_count, max_dead_event_count, min_dead_event_count, \"Dead\")).toDF\ndf_events.registerTempTable(\"df_events\")\n","dateUpdated":"2018-02-11T03:00:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class eventRecord\ndf_events: org.apache.spark.sql.DataFrame = [Average_Event: double, Max_Event: double ... 2 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]},"apps":[],"jobName":"paragraph_1518316249801_1459725574","id":"20170126-095056_275615884","dateCreated":"2018-02-11T02:30:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:528","user":"anonymous","dateFinished":"2018-02-11T03:00:22+0000","dateStarted":"2018-02-11T03:00:19+0000"},{"title":"Plot Event Count Grouped by Dead/Alive","text":"%sql\nselect * from df_events","dateUpdated":"2018-02-11T03:12:15+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":true,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"Mortality","index":3,"aggr":"sum"}],"groups":[],"values":[{"name":"Max_Event","index":1,"aggr":"sum"},{"name":"Min_Event","index":2,"aggr":"sum"},{"name":"Average_Event","index":0,"aggr":"sum"}]},"helium":{}}},"graph":{"mode":"table","height":300,"optionOpen":true,"keys":[{"name":"Max_Event","index":1,"aggr":"sum"},{"name":"Average_Event","index":0,"aggr":"sum"},{"name":"Min_Event","index":2,"aggr":"sum"}],"values":[{"name":"Max_Event","index":1,"aggr":"sum"},{"name":"Average_Event","index":0,"aggr":"sum"},{"name":"Min_Event","index":2,"aggr":"sum"}],"groups":[{"name":"Mortality","index":3,"aggr":"sum"}],"scatter":{"xAxis":{"name":"Average_Event","index":0,"aggr":"sum"},"yAxis":{"name":"Max_Event","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"Average_Event\tMax_Event\tMin_Event\tMortality\n683.1552587646077\t12627.0\t1.0\tAlive\n1027.7385229540919\t16829.0\t2.0\tDead\n"}]},"apps":[],"jobName":"paragraph_1518316249801_1459725574","id":"20170127-103258_1100387642","dateCreated":"2018-02-11T02:30:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:529","user":"anonymous","dateFinished":"2018-02-11T03:00:29+0000","dateStarted":"2018-02-11T03:00:29+0000"},{"title":"Testing Encounter Count - Don't change any cell starting from this one","text":"val  (avg_dead_encounter_count, max_dead_encounter_count, min_dead_encounter_count, avg_alive_encounter_count, max_alive_encounter_count, min_alive_encounter_count) = encounter_count_metrics(eventsRDD, mortalityRDD)","dateUpdated":"2018-02-11T03:00:37+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"avg_dead_encounter_count: Double = 24.839321357285428\nmax_dead_encounter_count: Double = 375.0\nmin_dead_encounter_count: Double = 1.0\navg_alive_encounter_count: Double = 18.695492487479132\nmax_alive_encounter_count: Double = 391.0\nmin_alive_encounter_count: Double = 1.0\n"}]},"apps":[],"jobName":"paragraph_1518316249802_1460879821","id":"20170126-085842_586212247","dateCreated":"2018-02-11T02:30:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:530","user":"anonymous","dateFinished":"2018-02-11T03:01:37+0000","dateStarted":"2018-02-11T03:00:37+0000"},{"title":"Populate the correct values in df_encounters dataframe","text":"case class encounterRecord(Average_Encounter: Double , Max_Encounter: Double, Min_Encounter: Double, Mortality: String)\n\nval df_encounter = Seq(encounterRecord(avg_alive_encounter_count, max_alive_encounter_count, min_alive_encounter_count, \"Alive\"), encounterRecord(avg_dead_encounter_count, max_dead_encounter_count, min_dead_encounter_count, \"Dead\")).toDF\ndf_encounter.registerTempTable(\"df_encounter\")\n","dateUpdated":"2018-02-11T03:01:43+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class encounterRecord\ndf_encounter: org.apache.spark.sql.DataFrame = [Average_Encounter: double, Max_Encounter: double ... 2 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]},"apps":[],"jobName":"paragraph_1518316249802_1460879821","id":"20170127-104258_320884595","dateCreated":"2018-02-11T02:30:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:531","user":"anonymous","dateFinished":"2018-02-11T03:01:44+0000","dateStarted":"2018-02-11T03:01:43+0000"},{"title":"Plot Encounter Count Grouped by Dead/Alive","text":"%sql\nselect * from df_encounter ","dateUpdated":"2018-02-11T03:14:59+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":true,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"Mortality","index":3,"aggr":"sum"}],"groups":[],"values":[{"name":"Max_Encounter","index":1,"aggr":"sum"},{"name":"Min_Encounter","index":2,"aggr":"sum"},{"name":"Average_Encounter","index":0,"aggr":"sum"}]},"helium":{}}},"graph":{"mode":"table","height":300,"optionOpen":true,"keys":[{"name":"Max_Encounter","index":1,"aggr":"sum"},{"name":"Average_Encounter","index":0,"aggr":"sum"},{"name":"Min_Encounter","index":2,"aggr":"sum"}],"values":[{"name":"Max_Encounter","index":1,"aggr":"sum"},{"name":"Average_Encounter","index":0,"aggr":"sum"},{"name":"Min_Encounter","index":2,"aggr":"sum"}],"groups":[{"name":"Mortality","index":3,"aggr":"sum"}],"scatter":{"xAxis":{"name":"Average_Encounter","index":0,"aggr":"sum"},"yAxis":{"name":"Max_Encounter","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"Average_Encounter\tMax_Encounter\tMin_Encounter\tMortality\n18.695492487479132\t391.0\t1.0\tAlive\n24.839321357285428\t375.0\t1.0\tDead\n"}]},"apps":[],"jobName":"paragraph_1518316249802_1460879821","id":"20170127-113147_1780103981","dateCreated":"2018-02-11T02:30:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:532","user":"anonymous","dateFinished":"2018-02-11T03:01:46+0000","dateStarted":"2018-02-11T03:01:46+0000"},{"text":"","dateUpdated":"2018-02-11T02:30:49+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518316249803_1460495072","id":"20170127-113337_1396101507","dateCreated":"2018-02-11T02:30:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:533"}],"name":"BDH_HW2_Zeppelin","id":"2D72YHA1V","angularObjects":{"2D56Y3ZQA:shared_process":[],"2D7MWCWGE:shared_process":[],"2D77ZZFPX:shared_process":[],"2D6M8B2SQ:shared_process":[],"2D614EMWZ:shared_process":[],"2D7C82HGK:shared_process":[],"2D7K4T4ZK:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}